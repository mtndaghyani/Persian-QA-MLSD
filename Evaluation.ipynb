{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHwcZHH4IRSZCZmivfoC9I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Evaluation Phase**\n","\n","In this notebook, we are going to evaluate different Question-Answering models with respect to the common evaluation metrics in this area.\n","First, we will implement these metrics and elaborate on the benefits and drawbacks of each. Then we will provide a model-agnostic evaluation module which will be exploited to evaluate and compare different models. "],"metadata":{"id":"8GZWsLixyKtc"}},{"cell_type":"markdown","source":["## Setting Up "],"metadata":{"id":"edXFQWll0JV7"}},{"cell_type":"code","source":["# Mount Google Drive to access files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCp-iE-30V77","executionInfo":{"status":"aborted","timestamp":1686253344415,"user_tz":-210,"elapsed":9,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"2f6b9887-0e6f-46a1-ec33-b8f00b3a4ff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["address = \"MLSys Course/project\" # Current directory\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(address))\n","\n","%cd /content/drive/My\\ Drive/$address\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vj5mLNTM0Wq_","executionInfo":{"status":"ok","timestamp":1686253289153,"user_tz":-210,"elapsed":5,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"6e9df5a5-2ff0-473b-8ab8-20f222339ac6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/MLSys Course/project\n"]}]},{"cell_type":"markdown","source":["### Importing required libraries"],"metadata":{"id":"Wtl0Gi-y0lQb"}},{"cell_type":"code","source":["!pip install hazm==0.7.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kstc7zU02Kvj","executionInfo":{"status":"ok","timestamp":1686253308727,"user_tz":-210,"elapsed":19577,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"4bd5d4bb-9c92-4e99-c586-817543cf2336"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hazm==0.7.0\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nltk==3.3 (from hazm==0.7.0)\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting libwapiti>=0.2.1 (from hazm==0.7.0)\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk==3.3->hazm==0.7.0) (1.16.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394475 sha256=ca10e008d088b18bca3c1657e67b3fc756df766ff477d7b848122cc3959a87c4\n","  Stored in directory: /root/.cache/pip/wheels/6b/6d/14/3defa4cd7013faeddf715150696f4a96d7725c87700eb8a68e\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp310-cp310-linux_x86_64.whl size=180377 sha256=e7a0eb93bcdb77d52f4205d13ea1950bfa35474e0ebd9a84b45c80146152dd5f\n","  Stored in directory: /root/.cache/pip/wheels/9f/cb/30/fef48ecac051e433987eccdb5682900b4c00d44a4bcd4d4ec8\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.8.1\n","    Uninstalling nltk-3.8.1:\n","      Successfully uninstalled nltk-3.8.1\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"4wxPEbzr0qa7","executionInfo":{"status":"ok","timestamp":1686253308727,"user_tz":-210,"elapsed":9,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## **Metrics**"],"metadata":{"id":"HP4XedOUy1qg"}},{"cell_type":"markdown","source":["### Exact Match (EM):\n","\n"," EM measures the percentage of questions for which the system provides the exact correct answer. It is a binary metric where a prediction is either marked as correct (1) if it exactly matches the gold-standard answer or incorrect (0) otherwise. EM is a stringent metric as even a slight deviation from the correct answer is considered incorrect."],"metadata":{"id":"y3odS6vAy5Dg"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"5ud_N25fx_Q1","executionInfo":{"status":"ok","timestamp":1686253308728,"user_tz":-210,"elapsed":9,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"outputs":[],"source":["def exact_match(predicted_answer, true_answer):\n","    return int(predicted_answer.lower() == true_answer.lower())"]},{"cell_type":"markdown","source":["### F1 Score:\n","\n"," The F1 score combines precision and recall to evaluate the overlap between predicted and correct answers. Precision measures the proportion of predicted answers that are correct, while recall measures the proportion of correct answers that are predicted. The F1 score is the harmonic mean of precision and recall and provides a balanced evaluation metric."],"metadata":{"id":"-fBEZomjzDKL"}},{"cell_type":"code","source":["def f1_score(predicted_answer, true_answer):\n","    predicted_tokens = set(predicted_answer.lower().split())\n","    true_tokens = set(true_answer.lower().split())\n","    \n","    if len(predicted_tokens) == 0 or len(true_tokens) == 0:\n","        return 0\n","    \n","    precision = len(predicted_tokens.intersection(true_tokens)) / len(predicted_tokens)\n","    recall = len(predicted_tokens.intersection(true_tokens)) / len(true_tokens)\n","    \n","    if precision + recall == 0:\n","        return 0\n","    \n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"],"metadata":{"id":"c6XOPXcVzHom","executionInfo":{"status":"ok","timestamp":1686253308728,"user_tz":-210,"elapsed":8,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### BLEU Score:\n","\n"," The Bilingual Evaluation Understudy (BLEU) is a metric commonly used in machine translation, but it can be adapted for QA evaluation. It compares the n-gram overlap between the predicted and reference answers. BLEU ranges from 0 to 1, where higher scores indicate better performance. However, BLEU is not always an ideal metric for QA as it primarily focuses on lexical overlap and does not capture semantic understanding."],"metadata":{"id":"_V8LfQwIzJ4G"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQjVL6swihxx","executionInfo":{"status":"ok","timestamp":1686253491997,"user_tz":-210,"elapsed":4330,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"46dafc5c-e9a9-4c00-c9b2-49968acd7870"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","def bleu_score(predicted_answer, true_answer):\n","    reference = [true_answer.split()]\n","    hypothesis = predicted_answer.split()\n","    \n","    smoothing_function = SmoothingFunction().method1\n","    \n","    bleu = sentence_bleu(reference, hypothesis, smoothing_function=smoothing_function)\n","    return bleu\n"],"metadata":{"id":"mKOETuJgzOQL","executionInfo":{"status":"ok","timestamp":1686253495064,"user_tz":-210,"elapsed":1,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### ROUGE Score:\n","\n"," The ROUGE (Recall-Oriented Understudy for Gisting Evaluation) metric is another evaluation measure initially developed for text summarization but can be adapted for QA. It calculates the overlap of n-grams (such as unigrams, bigrams, and longer sequences) between the predicted and reference answers. Like BLEU, higher ROUGE scores indicate better performance."],"metadata":{"id":"ZVGHwBtQzWJw"}},{"cell_type":"code","source":["!pip install rouge"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDBP_riBzaid","executionInfo":{"status":"ok","timestamp":1686253314410,"user_tz":-210,"elapsed":5690,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"222d2e67-1097-4366-db4c-d2f87448162f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]}]},{"cell_type":"code","source":["from rouge import Rouge\n","\n","def rouge_score(predicted_answer, true_answer):\n","    rouge = Rouge()\n","    scores = rouge.get_scores(predicted_answer, true_answer)\n","    return scores[0]['rouge-1']['f']"],"metadata":{"id":"XM1kWR8CzfpK","executionInfo":{"status":"ok","timestamp":1686253314411,"user_tz":-210,"elapsed":16,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## **Evaluation**"],"metadata":{"id":"d-_gMHZUzvXZ"}},{"cell_type":"markdown","source":["### Preparing the test set"],"metadata":{"id":"LqAstSBzz6S7"}},{"cell_type":"code","source":["PATH_TO_TEST_SET = './dataset/validation_2.csv'"],"metadata":{"id":"u_y9hSPYzu6z","executionInfo":{"status":"ok","timestamp":1686253314412,"user_tz":-210,"elapsed":16,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test_dataset = pd.read_csv(PATH_TO_TEST_SET, index_col=0)\n","test_dataset.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wEiB1MqU0gxh","executionInfo":{"status":"aborted","timestamp":1686253344415,"user_tz":-210,"elapsed":9,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"43ac1fd6-d009-4c09-e1b7-3913a2111d21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                       title  \\\n","3409          دانشگاه_شیکاگو   \n","909                   هوگنوت   \n","4679        پارلمان اسکاتلند   \n","4038             سیستم ایمنی   \n","267   نظریه پیچیدگی محاسباتی   \n","\n","                                                context  \\\n","3409  در سال 1929 ، پنجمین رئیس دانشگاه ، رابرت مینا...   \n","909   شاهزاده لویی دو کونده ، به همراه پسرانش دانیل ...   \n","4679  لوایح را می توان از طرق مختلف به پارلمان ارائه...   \n","4038  مکانیسم های استفاده شده برای فرار از سیستم ایم...   \n","267   کاهش متداول که استفاده می شود کاهش زمان چند جم...   \n","\n","                                               question           answers  \\\n","3409  رئیس پنجم دانشگاه در چه سالی سمت خود را به دست...              1929   \n","909   در چه سالی توافق برای اجازه حل و فصل زارلند حا...              1604   \n","4679  چه کسی می تواند قوانین جدید یا اصلاحاتی را در ...     دولت اسکاتلند   \n","4038  چه ترکیباتی را می توان با مولکولهای سلول میزبا...        آنتی ژن ها   \n","267   از چه اندازه گیری زمان در کاهش زمان چند جمله ا...  زمان چند جمله ای   \n","\n","      answer_start  \n","3409           7.0  \n","909          160.0  \n","4679          52.0  \n","4038         702.0  \n","267           88.0  "],"text/html":["\n","  <div id=\"df-c8fec5cf-a493-4250-a0f9-e146205aac79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answers</th>\n","      <th>answer_start</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3409</th>\n","      <td>دانشگاه_شیکاگو</td>\n","      <td>در سال 1929 ، پنجمین رئیس دانشگاه ، رابرت مینا...</td>\n","      <td>رئیس پنجم دانشگاه در چه سالی سمت خود را به دست...</td>\n","      <td>1929</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>909</th>\n","      <td>هوگنوت</td>\n","      <td>شاهزاده لویی دو کونده ، به همراه پسرانش دانیل ...</td>\n","      <td>در چه سالی توافق برای اجازه حل و فصل زارلند حا...</td>\n","      <td>1604</td>\n","      <td>160.0</td>\n","    </tr>\n","    <tr>\n","      <th>4679</th>\n","      <td>پارلمان اسکاتلند</td>\n","      <td>لوایح را می توان از طرق مختلف به پارلمان ارائه...</td>\n","      <td>چه کسی می تواند قوانین جدید یا اصلاحاتی را در ...</td>\n","      <td>دولت اسکاتلند</td>\n","      <td>52.0</td>\n","    </tr>\n","    <tr>\n","      <th>4038</th>\n","      <td>سیستم ایمنی</td>\n","      <td>مکانیسم های استفاده شده برای فرار از سیستم ایم...</td>\n","      <td>چه ترکیباتی را می توان با مولکولهای سلول میزبا...</td>\n","      <td>آنتی ژن ها</td>\n","      <td>702.0</td>\n","    </tr>\n","    <tr>\n","      <th>267</th>\n","      <td>نظریه پیچیدگی محاسباتی</td>\n","      <td>کاهش متداول که استفاده می شود کاهش زمان چند جم...</td>\n","      <td>از چه اندازه گیری زمان در کاهش زمان چند جمله ا...</td>\n","      <td>زمان چند جمله ای</td>\n","      <td>88.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8fec5cf-a493-4250-a0f9-e146205aac79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c8fec5cf-a493-4250-a0f9-e146205aac79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c8fec5cf-a493-4250-a0f9-e146205aac79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Wrapper Class\n","To provide a consistent interface for different models, we implement a wrapper parent class. For each model, we will inherit from this class and implement the ```preprocess``` and ```postprocess``` methods. Each method will convert the input format in a way that is appropriate for the main model.\n","The main model is passed as an argument when initializing an instance."],"metadata":{"id":"sUyv-BRDmk_R"}},{"cell_type":"code","source":["class ModelWrapperBase:\n","  def __init__(self, main_model):\n","    self.model = main_model\n","\n","  def preprocess(self, x):\n","    \"\"\"\n","    Preprocess the input so that it can be feeded to the main_model. Overload this method if necessary.\n","\n","    param x: is the input of the wrapper instance. It is a tuple: (context, question, answer_start)\n","    return: The appropriate input format for the main_model\n","    e.g: If your model just needs the \n","    'question' parameter as the input, you have to return the second item of the tuple.\n","    \"\"\"\n","    preprocessed = x # Preprocess the input x\n","    return preprocessed\n","  \n","  def postprocess(self, predicted_output):\n","    \"\"\"\n","    Postprocess the main_model's output. Overload this method if necessary.\n","\n","    param predicted_output: is the output of the main_model. It can be in any format.\n","    return: A string, which is the final predicted answer to the question.\n","    e.g: If the main_model's output is a tuple like (answer, length_of_answer), \n","    you need to gets the first item and return it.\n","    \"\"\"\n","    postprocessed = predicted_output # Postprocess the x\n","    return postprocessed\n","  \n","  def __call__(self, x):\n","    pre = self.preprocess(x)\n","    predicted = self.model(pre)\n","    post = self.postprocess(predicted)\n","    return post"],"metadata":{"id":"SjruUk14mkp5","executionInfo":{"status":"ok","timestamp":1686256806939,"user_tz":-210,"elapsed":402,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["class BaslineWrapper(ModelWrapperBase):\n","  def preprocess(self, x):\n","    return x[1]\n","  \n","  def postprocess(self, predicted_output):\n","    a = list(predicted_output.values())\n","    if len(a) == 0:\n","      return ' '\n","    pred = a[0]\n","    if len(pred) == 0:\n","      return ' '\n","    return pred\n","  \n","  def __call__(self, x):\n","    pre = self.preprocess(x)\n","    predicted = self.model.retrieve(pre, k=1)\n","    post = self.postprocess(predicted)\n","    return post"],"metadata":{"id":"6uhRq-rXqxi8","executionInfo":{"status":"ok","timestamp":1686256897627,"user_tz":-210,"elapsed":369,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["### Preparing the Model"],"metadata":{"id":"KvN9cx7g1P3j"}},{"cell_type":"code","source":["#################################################################################################################################\n","#                                                                                                                               #\n","#Please initialize and load your pretrained model here. Also, initialize an appropriate wrapper class and pass the model to it. #\n","#                             Finally, you can pass the wrapper object to the evaluation function.                              #\n","#                                                                                                                               #\n","#################################################################################################################################\n","\n","main_model = ... # Load your trained model here.\n","wrapper = ... # Initialize an instance of an appropriate wrapper class which you have already implemented. Pass this instance to the evaluation function."],"metadata":{"id":"E6u7x-eJl3zv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Baseline (VectorSpaceModel)**"],"metadata":{"id":"7sCZgBlSuA-S"}},{"cell_type":"code","source":["from baseline.indexes.positional_index import PositionalIndex\n","from baseline.preprocessor.persian_preprocessor import Preprocessor\n","from baseline.model.query_parser import  query_parse\n","from baseline.model.vector_space_model import VectorSpaceModel\n","\n","PATH_TO_TRAIN_SET = './dataset/train_2.csv'\n","\n","# Loading preprocessor\n","preprocessor = Preprocessor(PATH_TO_TRAIN_SET)\n","preprocessor.normalize()\n","preprocessor.lemmatize()\n","\n","pos_index = PositionalIndex(None)\n","pos_index.load('./baseline/indexes/pos_index.json')\n","\n","# Loading models\n","vs_model = VectorSpaceModel(pos_index, preprocessor, query_parse, to_retrieve='answers')\n","baseline = BaslineWrapper(vs_model)"],"metadata":{"id":"4MtE-19s1OSz","executionInfo":{"status":"ok","timestamp":1686256923377,"user_tz":-210,"elapsed":16309,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["### Running Evaluation"],"metadata":{"id":"2G2EhK5G1TG9"}},{"cell_type":"markdown","source":["The module will calculate the evaluation metrics (Exact Match, F1 Score, BLEU Score, and ROUGE Score) for each question-answer pair in the test set. It then calculates the overall scores and prints the evaluation results. The function also returns a dictionary containing the evaluation scores for further analysis or reporting."],"metadata":{"id":"6xi1khdU1jY0"}},{"cell_type":"code","source":["def evaluate_qa_model(qa_model, test_set):\n","    exact_match_scores = []\n","    f1_scores = []\n","    bleu_scores = []\n","    rouge_scores = []\n","    i = 0\n","    for index, row in test_set.iterrows():\n","        if i % 50 == 0:\n","          print(f'Processing index {i}')\n","        question = row['question']\n","        context = row['context']\n","        answer_start = row['answer_start']\n","        true_answer = row['answers']\n","        inp = (context, question, answer_start)\n","        \n","        # Generate predicted answer using the QA model\n","        predicted_answer = qa_model(inp)\n","        # Calculate evaluation metrics\n","        em = exact_match(predicted_answer, true_answer)\n","        f1 = f1_score(predicted_answer, true_answer)\n","        bleu = bleu_score(predicted_answer, true_answer)\n","        rouge = rouge_score(predicted_answer, true_answer)\n","        \n","        # Store the scores for each question\n","        exact_match_scores.append(em)\n","        f1_scores.append(f1)\n","        bleu_scores.append(bleu)\n","        rouge_scores.append(rouge)\n","        i += 1\n","    \n","    # Calculate the overall scores\n","    overall_exact_match = sum(exact_match_scores) / len(exact_match_scores)\n","    overall_f1 = sum(f1_scores) / len(f1_scores)\n","    overall_bleu = sum(bleu_scores) / len(bleu_scores)\n","    overall_rouge = sum(rouge_scores) / len(rouge_scores)\n","    \n","    # Print the evaluation results\n","    print(\"Evaluation Results:\")\n","    print(\"Exact Match (EM): {:.4f}\".format(overall_exact_match))\n","    print(\"F1 Score: {:.4f}\".format(overall_f1))\n","    print(\"BLEU Score: {:.4f}\".format(overall_bleu))\n","    print(\"ROUGE Score: {:.4f}\".format(overall_rouge))\n","    \n","    # Return the evaluation scores\n","    evaluation_scores = {\n","        'Exact Match': overall_exact_match,\n","        'F1 Score': overall_f1,\n","        'BLEU Score': overall_bleu,\n","        'ROUGE Score': overall_rouge\n","    }\n","    \n","    return evaluation_scores"],"metadata":{"id":"zOsvRQrA1lwH","executionInfo":{"status":"ok","timestamp":1686256928458,"user_tz":-210,"elapsed":354,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["evaluate_qa_model(baseline, test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBlqu0_T4h13","executionInfo":{"status":"ok","timestamp":1686257874641,"user_tz":-210,"elapsed":942506,"user":{"displayName":"Matin Daghyani","userId":"14129328762259957907"}},"outputId":"c837db7e-2af9-4811-e3bb-13f3a6b11359"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing index 0\n","Processing index 50\n","Processing index 100\n","Processing index 150\n","Processing index 200\n","Processing index 250\n","Processing index 300\n","Processing index 350\n","Processing index 400\n","Processing index 450\n","Processing index 500\n","Processing index 550\n","Processing index 600\n","Processing index 650\n","Processing index 700\n","Processing index 750\n","Processing index 800\n","Processing index 850\n","Processing index 900\n","Processing index 950\n","Processing index 1000\n","Processing index 1050\n","Processing index 1100\n","Processing index 1150\n","Processing index 1200\n","Processing index 1250\n","Processing index 1300\n","Processing index 1350\n","Processing index 1400\n","Processing index 1450\n","Processing index 1500\n","Processing index 1550\n","Processing index 1600\n","Processing index 1650\n","Processing index 1700\n","Processing index 1750\n","Processing index 1800\n","Processing index 1850\n","Processing index 1900\n","Processing index 1950\n","Processing index 2000\n","Processing index 2050\n","Processing index 2100\n","Processing index 2150\n","Processing index 2200\n","Processing index 2250\n","Processing index 2300\n","Processing index 2350\n","Processing index 2400\n","Processing index 2450\n","Processing index 2500\n","Processing index 2550\n","Processing index 2600\n","Processing index 2650\n","Processing index 2700\n","Processing index 2750\n","Processing index 2800\n","Processing index 2850\n","Processing index 2900\n","Processing index 2950\n","Processing index 3000\n","Processing index 3050\n","Processing index 3100\n","Processing index 3150\n","Processing index 3200\n","Evaluation Results:\n","Exact Match (EM): 0.0028\n","F1 Score: 0.0190\n","BLEU Score: 0.0038\n","ROUGE Score: 0.0192\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Exact Match': 0.0027820710973724882,\n"," 'F1 Score': 0.019000295819706015,\n"," 'BLEU Score': 0.0037798335567291383,\n"," 'ROUGE Score': 0.019207707855558556}"]},"metadata":{},"execution_count":57}]}]}